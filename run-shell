#!/bin/env bash
# ============================================================
#
# Run spark shell template 
#
# ============================================================

# set the default spark/hadoop conf directories

SPARK_SPECULATION=false
if grep -i -q servername1 <<<$(hostname); then
  SPARK_HOME=
elif grep -i -q servername1 <<<$(hostname); then
  SPARK_HOME=
fi

SPARK_CONF_DIR=
HADOOP_CONF_DIR=
QUEUE=

NUM_EXECUTORS=32
NUM_EXECUTOR_CORES=4
DEFAULT_PARALLELISM=$((4 * NUM_EXECUTOR_CORES * NUM_EXECUTORS))

# search the local lib/ directory for jars
JAR_DIR=lib
JARS="
  $JAR_DIR/spark-avro_2.11-3.2.0.jar,
  $JAR_DIR/scala-csv_2.11-1.3.4.jar,
  $(find target -name '*.jar' | tail -n 1)
"
spark-shell \
  --jars $(tr -d ' \n\t' <<<$JARS) \
  --master yarn \
  --deploy-mode client \
  --num-executors $NUM_EXECUTORS \
  --executor-cores $NUM_EXECUTOR_CORES \
  --executor-memory 32G \
  --conf spark.default.parallelism=$DEFAULT_PARALLELISM \
  --conf spark.yarn.executor.memoryOverhead=4G \
  --conf spark.sql.autoBroadcastJoinThreshold=-1 \
  --conf spark.sql.crossJoin.enabled=true \
  --conf spark.sql.pivotMaxValues=100000 \
  --conf spark.sql.shuffle.partitions=2048 \
  --conf spark.speculation=$SPARK_SPECULATION \
  --conf spark.speculation.interval=100ms \
  --conf spark.speculation.multiplier=1.5 \
  --conf spark.speculation.quantile=0.75 \
  --queue $QUEUE $@

